{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 17:40:16.730784: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import contractions\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "fakenews_pd = pd.read_csv(\"./Fake.csv\")\n",
    "realnews_pd = pd.read_csv(\"./True.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preliminary cleanup for accurate EDA, get rid of articles in the fakenews df that has\n",
    "# only empty spaces in the text column (like videos)\n",
    "\n",
    "fakenews_pd = fakenews_pd[~fakenews_pd['text'].isin(['  ', ' '])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fake news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "434.8654325850072"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fake news - average words per article\n",
    "\n",
    "fn_list = list(fakenews_pd['text'])\n",
    "fn_len = [len(item.split()) for item in fn_list]\n",
    "sum(fn_len)/len(fn_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.48181698831561"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fake news - average sentences per article\n",
    "\n",
    "fn_list_list = [[item] for item in fn_list]\n",
    "fn_list_len = [[len(item.split(\".\")) for item in sublist] for sublist in fn_list_list]\n",
    "fn_list_len = [item for sublist in fn_list_len for item in sublist]\n",
    "sum(fn_list_len)/len(fn_list_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    22851.000000\n",
       "mean        22.481817\n",
       "std         20.116143\n",
       "min          1.000000\n",
       "25%         12.000000\n",
       "50%         19.000000\n",
       "75%         27.000000\n",
       "max        556.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fake news sentence stats\n",
    "\n",
    "fake_sents = pd.Series(fn_list_len)\n",
    "fake_sents.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1290"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count fake articles with fewer than 4 sentences in text\n",
    "\n",
    "sum(i < 4 for i in fn_list_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "877"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count fake articles with fewer than 3 sentences in text\n",
    "\n",
    "sum(i < 3 for i in fn_list_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385.6400989867862"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# real news - average words per article\n",
    "\n",
    "rn_list = list(realnews_pd['text'])\n",
    "rn_len = [len(item.split()) for item in rn_list]\n",
    "sum(rn_len)/len(rn_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.982724004295655"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# real news - average sentences per article\n",
    "\n",
    "rn_list = list(realnews_pd['text'])\n",
    "rn_list_list = [[item] for item in rn_list]\n",
    "rn_list_len = [[len(item.split(\".\")) for item in sublist] for sublist in rn_list_list]\n",
    "rn_list_len = [item for sublist in rn_list_len for item in sublist]\n",
    "sum(rn_list_len)/len(rn_list_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    21417.000000\n",
       "mean        21.982724\n",
       "std         15.972420\n",
       "min          1.000000\n",
       "25%          9.000000\n",
       "50%         19.000000\n",
       "75%         30.000000\n",
       "max        283.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# real news sentence stats\n",
    "\n",
    "real_sents = pd.Series(rn_list_len)\n",
    "real_sents.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1290"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count fake articles with fewer than 4 sentences in text\n",
    "\n",
    "sum(i < 4 for i in fn_list_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count fake articles with fewer than 3 sentences in text\n",
    "\n",
    "sum(i < 3 for i in rn_list_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the text and title columns to lists for each data article data frame\n",
    "\n",
    "fn_list_text = fakenews_pd['text'].tolist()\n",
    "fn_list_title = fakenews_pd['title'].tolist()\n",
    "rn_list_text = realnews_pd['text'].tolist()\n",
    "rn_list_title = realnews_pd['title'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fake News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define fake news clean up function\n",
    "\n",
    "def fn_cleanup(list):\n",
    "\n",
    "    # remove periods from acronyms\n",
    "    fn_list_acro_fix = [re.sub(r'(?<!\\w)([A-Z])\\.', r'\\1', text) for text in list]\n",
    "\n",
    "    # remove twitter pics and credits\n",
    "    fn_list_no_twitpics = [re.sub(r'pic.twitter[\\S ]+?[\\d]{4}','', text) for text in fn_list_acro_fix]\n",
    "\n",
    "    # remove twitter handles\n",
    "    fn_list_no_twitter = [re.sub(r'\\(@_[\\w\\d]+\\)|\\(@[\\w\\d]+\\)|@[\\w\\d]+|@_[\\w\\d]+', ' ', text) for text in fn_list_no_twitpics]\n",
    "\n",
    "    # remove url links\n",
    "    fn_list_no_links = [re.sub(r'https\\:[\\S]+|pic.twitter[\\S]+','', text) for text in fn_list_no_twitter]\n",
    "\n",
    "    # remove photo credits\n",
    "    fn_list_no_photo_creds = [re.sub(r'Photo by[\\S ]+\\Z|Featured image[\\S ]+\\Z', '', text) for text in fn_list_no_links]\n",
    "\n",
    "    # remove hashtags\n",
    "    fn_list_no_hashtags = [re.sub(r'\\#[\\S]+', '', text) for text in fn_list_no_photo_creds]\n",
    "\n",
    "    # replace dashes with spaces\n",
    "    fn_list_no_dashes = [text.replace(\"-\", \" \") for text in fn_list_no_hashtags]\n",
    "\n",
    "    # separate sentences with space if no space after period\n",
    "    fn_list_add_spaces = [re.sub(r'((?<=[\\w\\d][\\.\\?\\!])[\\w\\d])', r' \\1', text) for text in fn_list_no_dashes]\n",
    "\n",
    "    # remove dates\n",
    "    fn_list_no_dates = [re.sub(r'[\\w]+ [\\d]{1,2}\\, [\\d]{4}', '', text) for text in fn_list_add_spaces]\n",
    "\n",
    "    # add space between dates and sentence beginnings\n",
    "    fn_list_fix_spaces = [re.sub(r'((?<=[0-9]{4})\\w)', r' \\1', text) for text in fn_list_no_dates]\n",
    "\n",
    "    # remove numbers if in the middle of words\n",
    "    fn_list_fix_alnums = [re.sub(r'(?<=[a-zA-Z])[\\d]+|(?<=[a-zA-Z])[\\d]+(?=[a-zA-Z])|[\\d]+(?=[a-zA-Z])', '', text) for text in fn_list_fix_spaces]\n",
    "\n",
    "    # join contractions with apostrophe (currently the 't' is separated with a space) then separate them into verb_not\n",
    "    fn_list_fix_conts1 = [re.sub(r'([a-zA-Z]+) (?=t )', r\"\\1'\", text).rstrip() for text in fn_list_fix_alnums]\n",
    "    fn_list_fix_conts2 = [re.sub(r'([a-zA-Z]+) (?=ll )', r\"\\1'\", text).rstrip() for text in fn_list_fix_conts1]\n",
    "    fn_list_fix_conts3 = [re.sub(r'([a-zA-Z]+) (?=s )', r\"\\1'\", text).rstrip() for text in fn_list_fix_conts2]\n",
    "    fn_list_fix_conts = [contractions.fix(text) for text in fn_list_fix_conts3]\n",
    "\n",
    "    return fn_list_fix_conts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up fake news whole text and title lists\n",
    "\n",
    "fn_cleanup_text = fn_cleanup(fn_list_text)\n",
    "fn_cleanup_title = fn_cleanup(fn_list_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define fake news transform function that shapes data to fit LSTM input\n",
    "\n",
    "def fn_consolidate(list):\n",
    "    \n",
    "    # sentence tokenize unless summary\n",
    "    if list == fn_cleanup_title or list == fn_cleanup_text:\n",
    "\n",
    "        fn_sent_toks = [sent_tokenize(item) for item in list]\n",
    "\n",
    "        # word tokenize\n",
    "        fn_word_tokens = [[word_tokenize(word) for word in sentence] for sentence in fn_sent_toks]\n",
    "\n",
    "    else:\n",
    "\n",
    "        # word tokenize\n",
    "        fn_word_tokens = [[word_tokenize(word) for word in sentence] for sentence in list]\n",
    "\n",
    "\n",
    "    # retain only words\n",
    "    fn_word_alphas = [[[word for word in sentence if word.isalpha()] for sentence in text] for text in fn_word_tokens]\n",
    "\n",
    "    # convert to lowercase\n",
    "    fn_word_lower = [[[word.lower() for word in sentence] for sentence in text] for text in fn_word_alphas]\n",
    "\n",
    "    # remove stop words\n",
    "    fn_word_nostops = [[[word for word in sentence if word not in stopwords.words('english')] for sentence in text] for text in fn_word_lower]\n",
    "\n",
    "    # lemmatize words\n",
    "    lem = WordNetLemmatizer()\n",
    "    # fn_words_lemma = [[[lem.lemmatize(word) for word in sentence] for sentence in text] for text in fn_word_lower]\n",
    "    fn_words_lemma = [[[lem.lemmatize(word) for word in sentence] for sentence in text] for text in fn_word_nostops]\n",
    "\n",
    "    # put words back into sentences (detokenize)\n",
    "    fn_words_detokenized = [[[TreebankWordDetokenizer().detokenize(sentence)] for sentence in text] for text in fn_words_lemma]\n",
    "\n",
    "    # group sentences in article back together\n",
    "    fn_sentences = [[sentence for sub_list in text for sentence in sub_list] for text in fn_words_detokenized]\n",
    "\n",
    "    # add periods back to ends of sentences so they can be identified by LSTM\n",
    "    fn_clean_text = [[(sentence + \". \") for sentence in text] for text in fn_sentences]\n",
    "    fn_clean_text_join = [\"\".join(text) for text in fn_clean_text]\n",
    "\n",
    "    return fn_clean_text_join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform fake news whole text and title lists\n",
    "\n",
    "fn_join_title = fn_consolidate(fn_cleanup_title)\n",
    "fn_join_text = fn_consolidate(fn_cleanup_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save transformed text as np arrays to be reloaded below\n",
    "\n",
    "fn_join_title_array = np.array(fn_join_title, dtype=object)\n",
    "fn_join_text_array = np.array(fn_join_text, dtype=object)\n",
    "np.save(\"fn_join_title\", fn_join_title_array)\n",
    "np.save(\"fn_join_text\", fn_join_text_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define real news clean up function\n",
    "\n",
    "def rn_cleanup(list):\n",
    "\n",
    "    # remove periods from acronyms\n",
    "    rn_list_acro_fix = [re.sub(r'(?<!\\w)([A-Z])\\.', r'\\1', text) for text in list]\n",
    "\n",
    "    # remove Reuters news desk locations\n",
    "    rn_list_no_newsdesk = [re.sub(r'\\A[\\S\\/. ]*\\(Reuters\\) - |NEW YORK/WASHINGTON (Reuters) - ','', text) for text in rn_list_acro_fix]\n",
    "\n",
    "    # remove twitter handles\n",
    "    rn_list_no_twitter = [re.sub(r'@[\\w]+|@_[\\w]+|\\(@_[\\w]+\\)', '', text) for text in rn_list_no_newsdesk]\n",
    "\n",
    "    # remove latin1 spaces ('xa0')\n",
    "    rn_list_no_twitter = [text.replace(u'\\xa0', u' ') for text in rn_list_no_twitter]\n",
    "\n",
    "    # remove bitly urls\n",
    "    rn_list_no_links = [re.sub(r' -- Source link: [\\S ]*\\Z|bit\\.ly[\\/\\w]+','', text) for text in rn_list_no_twitter]\n",
    "\n",
    "    # remove timestamps\n",
    "    rn_list_no_timestamps = [re.sub(r'\\[[\\w\\d:\\ ]*\\]','', text) for text in rn_list_no_links]\n",
    "\n",
    "    # Reuters prints a disclaimer before every twitter statement that the views expressed are not their own\n",
    "    rn_clean_list = [re.sub(r'The following [\\S ]+ \\: \\- ', '', text) for text in rn_list_no_timestamps]\n",
    "\n",
    "    # join contractions with apostrophe (currently the 't' is separated with a space) then separate them into verb_not\n",
    "    rn_list_fix_conts1 = [re.sub(r'([a-zA-Z]+) (?=t )', r\"\\1'\", text).rstrip() for text in rn_clean_list]\n",
    "    rn_list_fix_conts2 = [re.sub(r'([a-zA-Z]+) (?=ll )', r\"\\1'\", text).rstrip() for text in rn_list_fix_conts1]\n",
    "    rn_list_fix_conts3 = [re.sub(r'([a-zA-Z]+) (?=s )', r\"\\1'\", text).rstrip() for text in rn_list_fix_conts2]\n",
    "    rn_list_fix_conts = [contractions.fix(text) for text in rn_list_fix_conts3]\n",
    "\n",
    "    return rn_list_fix_conts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up real news whole text and title lists\n",
    "\n",
    "rn_cleanup_text = rn_cleanup(rn_list_text)\n",
    "rn_cleanup_title = rn_cleanup(rn_list_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define real news transform function that shapes data to fit LSTM input\n",
    "\n",
    "def rn_consolidate(list):\n",
    "\n",
    "    # sentence tokenize unless summary\n",
    "    if list == rn_cleanup_title or list == rn_cleanup_text:\n",
    "\n",
    "        rn_sent_toks = [sent_tokenize(item) for item in list]\n",
    "\n",
    "        # word tokenize\n",
    "        rn_word_tokens = [[word_tokenize(word) for word in sentence] for sentence in rn_sent_toks]\n",
    "\n",
    "    else:\n",
    "\n",
    "        # word tokenize\n",
    "        rn_word_tokens = [[word_tokenize(word) for word in sentence] for sentence in list]\n",
    "\n",
    "    # retain only words\n",
    "    rn_word_alphas = [[[word for word in sentence if word.isalpha()] for sentence in text] for text in rn_word_tokens]\n",
    "\n",
    "    # convert to lowercase\n",
    "    rn_word_lower = [[[word.lower() for word in sentence] for sentence in text] for text in rn_word_alphas]\n",
    "\n",
    "    # remove stop words\n",
    "    rn_word_nostops = [[[word for word in sentence if word not in stopwords.words('english')] for sentence in text] for text in rn_word_lower]\n",
    "\n",
    "    # lemmatize words\n",
    "    lem = WordNetLemmatizer()\n",
    "    # rn_words_lemma = [[[lem.lemmatize(word) for word in sentence] for sentence in text] for text in rn_word_lower]\n",
    "    rn_words_lemma = [[[lem.lemmatize(word) for word in sentence] for sentence in text] for text in rn_word_nostops]\n",
    "\n",
    "    # put words back into sentences (detokenize)\n",
    "    rn_words_detokenized = [[[TreebankWordDetokenizer().detokenize(sentence)] for sentence in text] for text in rn_words_lemma]\n",
    "\n",
    "    # group sentences in article back together\n",
    "    rn_sentences = [[sentence for sub_list in text for sentence in sub_list] for text in rn_words_detokenized]\n",
    "\n",
    "    # add periods back to ends of sentences so they can be identified by LSTM\n",
    "    rn_clean_text = [[(sentence + \". \") for sentence in text] for text in rn_sentences]\n",
    "    rn_clean_text_join = [\"\".join(text) for text in rn_clean_text]\n",
    "\n",
    "    return rn_clean_text_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform real news whole text and title lists\n",
    "\n",
    "rn_join_title = rn_consolidate(rn_cleanup_title)\n",
    "rn_join_text = rn_consolidate(rn_cleanup_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save processed text as np arrays to be reloaded below\n",
    "\n",
    "rn_join_title_array = np.array(rn_join_title, dtype=object)\n",
    "rn_join_text_array = np.array(rn_join_text, dtype=object)\n",
    "np.save(\"rn_join_title\", rn_join_title_array)\n",
    "np.save(\"rn_join_text\", rn_join_text_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define text rank function\n",
    "\n",
    "def text_summarize(text_list, num_sents):\n",
    "\n",
    "    from gensim.summarization.textcleaner import split_sentences\n",
    "    from gensim.summarization.summarizer import summarize\n",
    "\n",
    "    text_summaries = []\n",
    "    for text in text_list:\n",
    "        sentence_list = split_sentences(text)\n",
    "        sent_len = len(sentence_list)\n",
    "        if 0 < sent_len < num_sents:\n",
    "            text_summaries.append(sentence_list[:sent_len])\n",
    "        else:\n",
    "            temp_summaries = []\n",
    "            temp_summaries.append(summarize(text, word_count=200))\n",
    "            text_summaries.append(temp_summaries[0].split(\"\\n\", num_sents)[:num_sents])\n",
    "            \n",
    "    return text_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 3 and 4 sentence fake news summaries\n",
    "\n",
    "fn_summ3 = text_summarize(fn_cleanup_text, 3)\n",
    "fn_summ4 = text_summarize(fn_cleanup_text, 4)\n",
    "\n",
    "# transform 3 and 4 sentence fake news summaries\n",
    "\n",
    "fn_summ3_join = fn_consolidate(fn_summ3)\n",
    "fn_summ4_join = fn_consolidate(fn_summ4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save fake news summaries as np arrays to be reloaded below\n",
    "\n",
    "fn_join_summ3_array = np.array(fn_summ3_join, dtype=object)\n",
    "fn_join_summ4_array = np.array(fn_summ4_join, dtype=object)\n",
    "np.save(\"fn_join_summ3\", fn_join_summ3_array)\n",
    "np.save(\"fn_join_summ4\", fn_join_summ4_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 3 and 4 sentence real news summaries\n",
    "\n",
    "rn_summ3 = text_summarize(rn_cleanup_text, 3)\n",
    "rn_summ4 = text_summarize(rn_cleanup_text, 4)\n",
    "\n",
    "# transform 3 and 4 sentence real news summaries\n",
    "\n",
    "rn_summ3_join = fn_consolidate(rn_summ3)\n",
    "rn_summ4_join = fn_consolidate(rn_summ4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save real news summaries as np arrays to be reloaded below\n",
    "\n",
    "rn_join_summ3_array = np.array(rn_summ3_join, dtype=object)\n",
    "rn_join_summ4_array = np.array(rn_summ4_join, dtype=object)\n",
    "np.save(\"rn_join_summ3\", rn_join_summ3_array)\n",
    "np.save(\"rn_join_summ4\", rn_join_summ4_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column in realnews_pd with and add cleaned text to each row\n",
    "\n",
    "fn_clean_title_load = np.load(\"fn_join_title.npy\", allow_pickle=True).tolist()\n",
    "fn_clean_text_load = np.load(\"fn_join_text.npy\", allow_pickle=True).tolist()\n",
    "fn_clean_summ3_load = np.load(\"fn_join_summ3.npy\", allow_pickle=True).tolist()\n",
    "fn_clean_summ4_load = np.load(\"fn_join_summ4.npy\", allow_pickle=True).tolist()\n",
    "\n",
    "rn_clean_title_load = np.load(\"rn_join_title.npy\", allow_pickle=True).tolist()\n",
    "rn_clean_text_load = np.load(\"rn_join_text.npy\", allow_pickle=True).tolist()\n",
    "rn_clean_summ3_load = np.load(\"rn_join_summ3.npy\", allow_pickle=True).tolist()\n",
    "rn_clean_summ4_load = np.load(\"rn_join_summ4.npy\", allow_pickle=True).tolist()\n",
    "\n",
    "fakenews_pd['cleaned_title'] = fn_clean_title_load\n",
    "fakenews_pd['cleaned_text'] = fn_clean_text_load\n",
    "fakenews_pd['cleaned_summ3'] = fn_clean_summ3_load\n",
    "fakenews_pd['cleaned_summ4'] = fn_clean_summ4_load\n",
    "\n",
    "realnews_pd['cleaned_title'] = rn_clean_title_load\n",
    "realnews_pd['cleaned_text'] = rn_clean_text_load\n",
    "realnews_pd['cleaned_summ3'] = rn_clean_summ3_load\n",
    "realnews_pd['cleaned_summ4'] = rn_clean_summ4_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>cleaned_title</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cleaned_summ3</th>\n",
       "      <th>cleaned_summ4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mistrial declared in corruption case against e...</td>\n",
       "      <td>LOS ANGELES (Reuters) - A federal judge declar...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 22, 2016</td>\n",
       "      <td>mistrial declared corruption case angeles sher...</td>\n",
       "      <td>federal judge declared mistrial thursday obstr...</td>\n",
       "      <td>federal judge declared mistrial thursday obstr...</td>\n",
       "      <td>federal judge declared mistrial thursday obstr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China says hopes all parties can resolve North...</td>\n",
       "      <td>BEIJING (Reuters) - China s Foreign Ministry s...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>November 21, 2017</td>\n",
       "      <td>china say hope party resolve north korea issue...</td>\n",
       "      <td>china foreign ministry said tuesday hoped part...</td>\n",
       "      <td>china foreign ministry said tuesday hoped part...</td>\n",
       "      <td>china foreign ministry said tuesday hoped part...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ivanka Trump-Branded Cheapo Scarves Recalled ...</td>\n",
       "      <td>Ivanka Trump s stab at using her dad s name to...</td>\n",
       "      <td>News</td>\n",
       "      <td>April 7, 2016</td>\n",
       "      <td>ivanka trump branded cheapo scarf recalled eas...</td>\n",
       "      <td>ivanka trump stab using dad name sell cheap pr...</td>\n",
       "      <td>ivanka trump stab using dad name sell cheap pr...</td>\n",
       "      <td>ivanka trump stab using dad name sell cheap pr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Has Ruined His Own Name So Badly His Ho...</td>\n",
       "      <td>Donald Trump probably thought that running for...</td>\n",
       "      <td>News</td>\n",
       "      <td>October 21, 2016</td>\n",
       "      <td>trump ruined name badly hotel resort drastic s...</td>\n",
       "      <td>donald trump probably thought running presiden...</td>\n",
       "      <td>name stay existing hotel new one carry name sc...</td>\n",
       "      <td>name stay existing hotel new one carry name sc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRUMP WAS RIGHT About CNN Being “Very Fake New...</td>\n",
       "      <td>Everyone laughing after Trump rebranded CNN as...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Feb 17, 2017</td>\n",
       "      <td>trump right cnn fake news federal judge rule c...</td>\n",
       "      <td>everyone laughing trump rebranded cnn go netwo...</td>\n",
       "      <td>judge orinda evans declare cnn peddling falseh...</td>\n",
       "      <td>judge orinda evans declare cnn peddling falseh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Mistrial declared in corruption case against e...   \n",
       "1  China says hopes all parties can resolve North...   \n",
       "2   Ivanka Trump-Branded Cheapo Scarves Recalled ...   \n",
       "3   Trump Has Ruined His Own Name So Badly His Ho...   \n",
       "4  TRUMP WAS RIGHT About CNN Being “Very Fake New...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  LOS ANGELES (Reuters) - A federal judge declar...  politicsNews   \n",
       "1  BEIJING (Reuters) - China s Foreign Ministry s...     worldnews   \n",
       "2  Ivanka Trump s stab at using her dad s name to...          News   \n",
       "3  Donald Trump probably thought that running for...          News   \n",
       "4  Everyone laughing after Trump rebranded CNN as...      politics   \n",
       "\n",
       "                 date                                      cleaned_title  \\\n",
       "0  December 22, 2016   mistrial declared corruption case angeles sher...   \n",
       "1  November 21, 2017   china say hope party resolve north korea issue...   \n",
       "2       April 7, 2016  ivanka trump branded cheapo scarf recalled eas...   \n",
       "3    October 21, 2016  trump ruined name badly hotel resort drastic s...   \n",
       "4        Feb 17, 2017  trump right cnn fake news federal judge rule c...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  federal judge declared mistrial thursday obstr...   \n",
       "1  china foreign ministry said tuesday hoped part...   \n",
       "2  ivanka trump stab using dad name sell cheap pr...   \n",
       "3  donald trump probably thought running presiden...   \n",
       "4  everyone laughing trump rebranded cnn go netwo...   \n",
       "\n",
       "                                       cleaned_summ3  \\\n",
       "0  federal judge declared mistrial thursday obstr...   \n",
       "1  china foreign ministry said tuesday hoped part...   \n",
       "2  ivanka trump stab using dad name sell cheap pr...   \n",
       "3  name stay existing hotel new one carry name sc...   \n",
       "4  judge orinda evans declare cnn peddling falseh...   \n",
       "\n",
       "                                       cleaned_summ4  label  \n",
       "0  federal judge declared mistrial thursday obstr...      0  \n",
       "1  china foreign ministry said tuesday hoped part...      0  \n",
       "2  ivanka trump stab using dad name sell cheap pr...      1  \n",
       "3  name stay existing hotel new one carry name sc...      1  \n",
       "4  judge orinda evans declare cnn peddling falseh...      1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add label column with 1 for fakenews and 0 for realnews\n",
    "fakenews_pd['label'] = 1\n",
    "realnews_pd['label'] = 0\n",
    "\n",
    "# combine the dataframes, shuffle rows, and reset the index\n",
    "news = [fakenews_pd, realnews_pd]\n",
    "news_df = pd.concat(news).sample(frac = 1)\n",
    "news_df.reset_index(inplace=True)\n",
    "news_df.drop(columns = ['index'], inplace=True)\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data frame as pickle\n",
    "\n",
    "news_df.to_pickle(\"news_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved pickle as dataframe\n",
    "\n",
    "news_df = pd.read_pickle(\"news_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training, validation, and test sets\n",
    "\n",
    "xtrainvalid1, xtest1, ytrainvalid1, ytest1 = train_test_split(news_df.cleaned_title.values, news_df.label, test_size=0.1, shuffle=True)\n",
    "xtrainvalid2, xtest2, ytrainvalid2, ytest2 = train_test_split(news_df.cleaned_text.values, news_df.label, test_size=0.1, shuffle=True)\n",
    "xtrainvalid3, xtest3, ytrainvalid3, ytest3 = train_test_split(news_df.cleaned_summ3.values, news_df.label, test_size=0.1, shuffle=True)\n",
    "xtrainvalid4, xtest4, ytrainvalid4, ytest4 = train_test_split(news_df.cleaned_summ4.values, news_df.label, test_size=0.1, shuffle=True)\n",
    "\n",
    "xtrain1, xvalid1, ytrain1, yvalid1 = train_test_split(xtrainvalid1, ytrainvalid1, test_size=0.1, shuffle=True)\n",
    "xtrain2, xvalid2, ytrain2, yvalid2 = train_test_split(xtrainvalid2, ytrainvalid2, test_size=0.1, shuffle=True)\n",
    "xtrain3, xvalid3, ytrain3, yvalid3 = train_test_split(xtrainvalid3, ytrainvalid3, test_size=0.1, shuffle=True)\n",
    "xtrain4, xvalid4, ytrain4, yvalid4 = train_test_split(xtrainvalid4, ytrainvalid4, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare hyperparameters\n",
    "\n",
    "VOCABULARY_SIZE = 20000\n",
    "MAX_LENGTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embeddings index\n",
    "\n",
    "embeddings_index = {}\n",
    "\n",
    "f = open('./glove.6B.50d.txt',encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vocabulary based on words in each training set\n",
    "\n",
    "tokenizer = Tokenizer(num_words=VOCABULARY_SIZE)\n",
    "tokenizer.fit_on_texts(list(xtrain1) + list(xvalid1) + list(xtest1))\n",
    "tokenizer.fit_on_texts(list(xtrain2) + list(xvalid2) + list(xtest2))\n",
    "tokenizer.fit_on_texts(list(xtrain3) + list(xvalid3) + list(xtest3))\n",
    "tokenizer.fit_on_texts(list(xtrain4) + list(xvalid4) + list(xtest4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tokens to numerical sequences\n",
    "\n",
    "xtrain_sequence1 = tokenizer.texts_to_sequences(xtrain1)\n",
    "xvalid_sequence1 = tokenizer.texts_to_sequences(xvalid1)\n",
    "xtest_sequence1 = tokenizer.texts_to_sequences(xtest1)\n",
    "\n",
    "xtrain_sequence2 = tokenizer.texts_to_sequences(xtrain2)\n",
    "xvalid_sequence2 = tokenizer.texts_to_sequences(xvalid2)\n",
    "xtest_sequence2 = tokenizer.texts_to_sequences(xtest2)\n",
    "\n",
    "xtrain_sequence3 = tokenizer.texts_to_sequences(xtrain3)\n",
    "xvalid_sequence3 = tokenizer.texts_to_sequences(xvalid3)\n",
    "xtest_sequence3 = tokenizer.texts_to_sequences(xtest3)\n",
    "\n",
    "xtrain_sequence4 = tokenizer.texts_to_sequences(xtrain4)\n",
    "xvalid_sequence4 = tokenizer.texts_to_sequences(xvalid4)\n",
    "xtest_sequence4 = tokenizer.texts_to_sequences(xtest4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import LSTM features\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.utils import np_utils, pad_sequences\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad sequences so all sequences are of equal length\n",
    "\n",
    "xtrain_padding1 = pad_sequences(xtrain_sequence1, maxlen=MAX_LENGTH)\n",
    "xvalid_padding1 = pad_sequences(xvalid_sequence1, maxlen=MAX_LENGTH)\n",
    "xtest_padding1 = pad_sequences(xtest_sequence1, maxlen=MAX_LENGTH)\n",
    "\n",
    "xtrain_padding2 = pad_sequences(xtrain_sequence2, maxlen=MAX_LENGTH)\n",
    "xvalid_padding2 = pad_sequences(xvalid_sequence2, maxlen=MAX_LENGTH)\n",
    "xtest_padding2 = pad_sequences(xtest_sequence2, maxlen=MAX_LENGTH)\n",
    "\n",
    "xtrain_padding3 = pad_sequences(xtrain_sequence3, maxlen=MAX_LENGTH)\n",
    "xvalid_padding3 = pad_sequences(xvalid_sequence3, maxlen=MAX_LENGTH)\n",
    "xtest_padding3 = pad_sequences(xtest_sequence3, maxlen=MAX_LENGTH)\n",
    "\n",
    "xtrain_padding4 = pad_sequences(xtrain_sequence4, maxlen=MAX_LENGTH)\n",
    "xvalid_padding4 = pad_sequences(xvalid_sequence4, maxlen=MAX_LENGTH)\n",
    "xtest_padding4 = pad_sequences(xtest_sequence4, maxlen=MAX_LENGTH)\n",
    "\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embedding matrix \n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 50))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode binary labels as sparse vectors\n",
    "\n",
    "ytrain_encode1 = np_utils.to_categorical(ytrain1)\n",
    "yvalid_encode1 = np_utils.to_categorical(yvalid1)\n",
    "ytest_encode1 = np_utils.to_categorical(ytest1)\n",
    "\n",
    "ytrain_encode2 = np_utils.to_categorical(ytrain2)\n",
    "yvalid_encode2 = np_utils.to_categorical(yvalid2)\n",
    "ytest_encode2 = np_utils.to_categorical(ytest2)\n",
    "\n",
    "ytrain_encode3 = np_utils.to_categorical(ytrain3)\n",
    "yvalid_encode3 = np_utils.to_categorical(yvalid3)\n",
    "ytest_encode3 = np_utils.to_categorical(ytest3)\n",
    "\n",
    "ytrain_encode4 = np_utils.to_categorical(ytrain4)\n",
    "yvalid_encode4 = np_utils.to_categorical(yvalid4)\n",
    "ytest_encode4 = np_utils.to_categorical(ytest4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 18:09:49.791319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 18:09:49.803302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 18:09:49.803718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 18:09:49.804280: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 18:09:49.804932: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 18:09:49.805249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 18:09:49.805523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 18:09:50.295332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 18:09:50.295635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 18:09:50.295870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 18:09:50.296124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2048 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# create bidirectional LSTM model for titles\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(len(word_index) + 1,\n",
    " 50,\n",
    " weights=[embedding_matrix],\n",
    " input_length=MAX_LENGTH,\n",
    " trainable=False))\n",
    "model1.add(SpatialDropout1D(0.3))\n",
    "model1.add(Bidirectional(LSTM(100, dropout=0.3, recurrent_dropout=0.3)))\n",
    "model1.add(Dense(1024, activation='relu'))\n",
    "model1.add(Dropout(0.8))\n",
    "model1.add(Dense(1024, activation='relu'))\n",
    "model1.add(Dropout(0.8))\n",
    "model1.add(Dense(2))\n",
    "model1.add(Activation('sigmoid'))\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 18:09:54.867412: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 50s 650ms/step - loss: 0.4139 - accuracy: 0.8053 - val_loss: 0.2771 - val_accuracy: 0.8891\n",
      "Epoch 2/20\n",
      "71/71 [==============================] - 46s 643ms/step - loss: 0.3092 - accuracy: 0.8669 - val_loss: 0.2325 - val_accuracy: 0.9056\n",
      "Epoch 3/20\n",
      "71/71 [==============================] - 44s 620ms/step - loss: 0.2833 - accuracy: 0.8804 - val_loss: 0.2159 - val_accuracy: 0.9132\n",
      "Epoch 4/20\n",
      "71/71 [==============================] - 44s 619ms/step - loss: 0.2667 - accuracy: 0.8881 - val_loss: 0.2062 - val_accuracy: 0.9199\n",
      "Epoch 5/20\n",
      "71/71 [==============================] - 45s 629ms/step - loss: 0.2544 - accuracy: 0.8928 - val_loss: 0.1988 - val_accuracy: 0.9179\n",
      "Epoch 6/20\n",
      "71/71 [==============================] - 44s 620ms/step - loss: 0.2433 - accuracy: 0.8981 - val_loss: 0.1959 - val_accuracy: 0.9227\n",
      "Epoch 7/20\n",
      "71/71 [==============================] - 44s 626ms/step - loss: 0.2374 - accuracy: 0.9019 - val_loss: 0.1903 - val_accuracy: 0.9207\n",
      "Epoch 8/20\n",
      "71/71 [==============================] - 45s 631ms/step - loss: 0.2335 - accuracy: 0.9020 - val_loss: 0.1868 - val_accuracy: 0.9194\n",
      "Epoch 9/20\n",
      "71/71 [==============================] - 45s 637ms/step - loss: 0.2268 - accuracy: 0.9051 - val_loss: 0.1846 - val_accuracy: 0.9220\n",
      "Epoch 10/20\n",
      "71/71 [==============================] - 42s 595ms/step - loss: 0.2222 - accuracy: 0.9082 - val_loss: 0.1882 - val_accuracy: 0.9227\n",
      "Epoch 11/20\n",
      "71/71 [==============================] - 42s 593ms/step - loss: 0.2148 - accuracy: 0.9118 - val_loss: 0.1838 - val_accuracy: 0.9267\n",
      "Epoch 12/20\n",
      "71/71 [==============================] - 42s 592ms/step - loss: 0.2150 - accuracy: 0.9108 - val_loss: 0.1765 - val_accuracy: 0.9240\n",
      "Epoch 13/20\n",
      "71/71 [==============================] - 45s 640ms/step - loss: 0.2164 - accuracy: 0.9106 - val_loss: 0.1733 - val_accuracy: 0.9285\n",
      "Epoch 14/20\n",
      "71/71 [==============================] - 46s 655ms/step - loss: 0.2117 - accuracy: 0.9118 - val_loss: 0.1730 - val_accuracy: 0.9262\n",
      "Epoch 15/20\n",
      "71/71 [==============================] - 44s 624ms/step - loss: 0.2103 - accuracy: 0.9141 - val_loss: 0.1686 - val_accuracy: 0.9322\n",
      "Epoch 16/20\n",
      "71/71 [==============================] - 43s 612ms/step - loss: 0.2046 - accuracy: 0.9169 - val_loss: 0.1748 - val_accuracy: 0.9285\n",
      "Epoch 17/20\n",
      "71/71 [==============================] - 43s 599ms/step - loss: 0.2015 - accuracy: 0.9169 - val_loss: 0.1814 - val_accuracy: 0.9230\n",
      "Epoch 18/20\n",
      "71/71 [==============================] - 43s 604ms/step - loss: 0.2079 - accuracy: 0.9145 - val_loss: 0.1704 - val_accuracy: 0.9315\n",
      "Epoch 19/20\n",
      "71/71 [==============================] - 43s 602ms/step - loss: 0.2022 - accuracy: 0.9169 - val_loss: 0.1680 - val_accuracy: 0.9312\n",
      "Epoch 20/20\n",
      "71/71 [==============================] - 44s 624ms/step - loss: 0.1996 - accuracy: 0.9193 - val_loss: 0.1719 - val_accuracy: 0.9322\n"
     ]
    }
   ],
   "source": [
    "# fit title model with the training data\n",
    "\n",
    "history1 = model1.fit(xtrain_padding1, y=ytrain_encode1, batch_size=512, validation_data=(xvalid_padding1, yvalid_encode1), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: title_b.hd5/assets\n"
     ]
    }
   ],
   "source": [
    "# save title model\n",
    "\n",
    "model1.save(\"title_b.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 69ms/step\n"
     ]
    }
   ],
   "source": [
    "# predict on test set\n",
    "\n",
    "y_pred1 = model1.predict(x = xtest_padding1, batch_size = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the prediction probability scores to binaries\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred_class1 = np.where(y_pred1 > threshold, 1, 0)\n",
    "\n",
    "\n",
    "y_pred_int1 = []\n",
    "for i in range(len(y_pred_class1)):\n",
    "    if y_pred_class1[i][0] == 1:\n",
    "        y_pred_int1.append(0)\n",
    "    elif y_pred_class1[i][0] == 0:\n",
    "        y_pred_int1.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2056,  187],\n",
       "       [ 105, 2079]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_pred_int1, ytest1)\n",
    "cm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['titles', 0.9174757281553398, 0.9519230769230769, 0.9340411113620962]\n"
     ]
    }
   ],
   "source": [
    "# calculate prediction score\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "p1 = precision_score(y_pred_int1, ytest1)\n",
    "r1 = recall_score(y_pred_int1, ytest1)\n",
    "a1 = accuracy_score(y_pred_int1, ytest1)\n",
    "perf1 = [\"titles\",p1,r1,a1]\n",
    "print(perf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# create bidirectional LSTM model for whole texts\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(len(word_index) + 1,\n",
    " 50,\n",
    " weights=[embedding_matrix],\n",
    " input_length=MAX_LENGTH,\n",
    " trainable=False))\n",
    "model2.add(SpatialDropout1D(0.3))\n",
    "model2.add(Bidirectional(LSTM(100, dropout=0.3, recurrent_dropout=0.3)))\n",
    "model2.add(Dense(1024, activation='relu'))\n",
    "model2.add(Dropout(0.8))\n",
    "model2.add(Dense(1024, activation='relu'))\n",
    "model2.add(Dropout(0.8))\n",
    "model2.add(Dense(2))\n",
    "model2.add(Activation('sigmoid'))\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "71/71 [==============================] - 46s 613ms/step - loss: 0.3840 - accuracy: 0.8262 - val_loss: 0.2073 - val_accuracy: 0.9230\n",
      "Epoch 2/30\n",
      "71/71 [==============================] - 43s 608ms/step - loss: 0.2597 - accuracy: 0.8974 - val_loss: 0.1841 - val_accuracy: 0.9315\n",
      "Epoch 3/30\n",
      "71/71 [==============================] - 42s 597ms/step - loss: 0.2305 - accuracy: 0.9120 - val_loss: 0.3660 - val_accuracy: 0.8876\n",
      "Epoch 4/30\n",
      "71/71 [==============================] - 43s 605ms/step - loss: 0.2115 - accuracy: 0.9211 - val_loss: 0.2890 - val_accuracy: 0.9089\n",
      "Epoch 5/30\n",
      "71/71 [==============================] - 43s 600ms/step - loss: 0.1845 - accuracy: 0.9321 - val_loss: 0.1463 - val_accuracy: 0.9513\n",
      "Epoch 6/30\n",
      "71/71 [==============================] - 42s 597ms/step - loss: 0.1885 - accuracy: 0.9307 - val_loss: 0.1576 - val_accuracy: 0.9496\n",
      "Epoch 7/30\n",
      "71/71 [==============================] - 43s 605ms/step - loss: 0.1698 - accuracy: 0.9378 - val_loss: 0.3355 - val_accuracy: 0.9046\n",
      "Epoch 8/30\n",
      "71/71 [==============================] - 45s 632ms/step - loss: 0.1493 - accuracy: 0.9460 - val_loss: 0.2411 - val_accuracy: 0.9358\n",
      "Epoch 9/30\n",
      "71/71 [==============================] - 44s 613ms/step - loss: 0.1445 - accuracy: 0.9480 - val_loss: 0.2726 - val_accuracy: 0.9129\n",
      "Epoch 10/30\n",
      "71/71 [==============================] - 42s 591ms/step - loss: 0.1499 - accuracy: 0.9471 - val_loss: 0.3154 - val_accuracy: 0.9222\n",
      "Epoch 11/30\n",
      "71/71 [==============================] - 42s 592ms/step - loss: 0.1401 - accuracy: 0.9501 - val_loss: 0.1146 - val_accuracy: 0.9609\n",
      "Epoch 12/30\n",
      "71/71 [==============================] - 44s 613ms/step - loss: 0.1301 - accuracy: 0.9545 - val_loss: 0.1776 - val_accuracy: 0.9307\n",
      "Epoch 13/30\n",
      "71/71 [==============================] - 44s 624ms/step - loss: 0.1234 - accuracy: 0.9564 - val_loss: 0.1304 - val_accuracy: 0.9541\n",
      "Epoch 14/30\n",
      "71/71 [==============================] - 42s 592ms/step - loss: 0.1251 - accuracy: 0.9555 - val_loss: 0.1614 - val_accuracy: 0.9420\n",
      "Epoch 15/30\n",
      "71/71 [==============================] - 42s 590ms/step - loss: 0.1167 - accuracy: 0.9603 - val_loss: 0.1288 - val_accuracy: 0.9583\n",
      "Epoch 16/30\n",
      "71/71 [==============================] - 42s 597ms/step - loss: 0.1202 - accuracy: 0.9576 - val_loss: 0.1476 - val_accuracy: 0.9538\n",
      "Epoch 17/30\n",
      "71/71 [==============================] - 42s 598ms/step - loss: 0.1127 - accuracy: 0.9602 - val_loss: 0.1197 - val_accuracy: 0.9654\n",
      "Epoch 18/30\n",
      "71/71 [==============================] - 43s 613ms/step - loss: 0.1070 - accuracy: 0.9624 - val_loss: 0.0913 - val_accuracy: 0.9714\n",
      "Epoch 19/30\n",
      "71/71 [==============================] - 45s 633ms/step - loss: 0.1149 - accuracy: 0.9586 - val_loss: 0.1249 - val_accuracy: 0.9604\n",
      "Epoch 20/30\n",
      "71/71 [==============================] - 43s 609ms/step - loss: 0.1005 - accuracy: 0.9644 - val_loss: 0.0980 - val_accuracy: 0.9671\n",
      "Epoch 21/30\n",
      "71/71 [==============================] - 43s 613ms/step - loss: 0.1079 - accuracy: 0.9616 - val_loss: 0.0984 - val_accuracy: 0.9709\n",
      "Epoch 22/30\n",
      "71/71 [==============================] - 43s 603ms/step - loss: 0.0985 - accuracy: 0.9660 - val_loss: 0.1572 - val_accuracy: 0.9478\n",
      "Epoch 23/30\n",
      "71/71 [==============================] - 44s 614ms/step - loss: 0.1198 - accuracy: 0.9568 - val_loss: 0.1624 - val_accuracy: 0.9531\n",
      "Epoch 24/30\n",
      "71/71 [==============================] - 44s 615ms/step - loss: 0.0956 - accuracy: 0.9666 - val_loss: 0.0976 - val_accuracy: 0.9664\n",
      "Epoch 25/30\n",
      "71/71 [==============================] - 42s 596ms/step - loss: 0.0936 - accuracy: 0.9677 - val_loss: 0.1074 - val_accuracy: 0.9704\n",
      "Epoch 26/30\n",
      "71/71 [==============================] - 43s 610ms/step - loss: 0.0872 - accuracy: 0.9691 - val_loss: 0.1606 - val_accuracy: 0.9553\n",
      "Epoch 27/30\n",
      "71/71 [==============================] - 43s 601ms/step - loss: 0.0949 - accuracy: 0.9676 - val_loss: 0.1688 - val_accuracy: 0.9471\n",
      "Epoch 28/30\n",
      "71/71 [==============================] - 43s 608ms/step - loss: 0.1024 - accuracy: 0.9631 - val_loss: 0.0849 - val_accuracy: 0.9706\n",
      "Epoch 29/30\n",
      "71/71 [==============================] - 43s 609ms/step - loss: 0.0888 - accuracy: 0.9701 - val_loss: 0.0831 - val_accuracy: 0.9742\n",
      "Epoch 30/30\n",
      "71/71 [==============================] - 43s 602ms/step - loss: 0.0838 - accuracy: 0.9705 - val_loss: 0.1063 - val_accuracy: 0.9676\n"
     ]
    }
   ],
   "source": [
    "# fit model with the training data\n",
    "\n",
    "history2 = model2.fit(xtrain_padding2, y=ytrain_encode2, batch_size=512, validation_data=(xvalid_padding2, yvalid_encode2), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: full_text_b.hd5/assets\n"
     ]
    }
   ],
   "source": [
    "# save whole text model data\n",
    "\n",
    "model2.save(\"full_text_b.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 67ms/step\n"
     ]
    }
   ],
   "source": [
    "# predict on test set\n",
    "\n",
    "y_pred2 = model2.predict(x = xtest_padding2, batch_size = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert probabilities to binaries\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred_class2 = np.where(y_pred2 > threshold, 1, 0)\n",
    "y_pred_int2 = []\n",
    "for i in range(len(y_pred_class2)):\n",
    "    if y_pred_class2[i][0] == 1:\n",
    "        y_pred_int2.append(0)\n",
    "    elif y_pred_class2[i][0] == 0:\n",
    "        y_pred_int2.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2002,   20],\n",
       "       [ 134, 2271]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm2 = confusion_matrix(y_pred_int2, ytest2)\n",
    "cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['whole texts', 0.9912701876909646, 0.9442827442827443, 0.9652134628416534]\n"
     ]
    }
   ],
   "source": [
    "# calculate performance scores\n",
    "\n",
    "p2 = precision_score(y_pred_int2, ytest2)\n",
    "r2 = recall_score(y_pred_int2, ytest2)\n",
    "a2 = accuracy_score(y_pred_int2, ytest2)\n",
    "perf2 = [\"whole texts\",p2,r2,a2]\n",
    "print(perf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# create bidirectional LSTM model for 3 sentence summaries\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(len(word_index) + 1,\n",
    " 50,\n",
    " weights=[embedding_matrix],\n",
    " input_length=MAX_LENGTH,\n",
    " trainable=False))\n",
    "model3.add(SpatialDropout1D(0.3))\n",
    "model3.add(Bidirectional(LSTM(100, dropout=0.3, recurrent_dropout=0.3)))\n",
    "model3.add(Dense(1024, activation='relu'))\n",
    "model3.add(Dropout(0.8))\n",
    "model3.add(Dense(1024, activation='relu'))\n",
    "model3.add(Dropout(0.8))\n",
    "model3.add(Dense(2))\n",
    "model3.add(Activation('sigmoid'))\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "71/71 [==============================] - 45s 603ms/step - loss: 0.4671 - accuracy: 0.7809 - val_loss: 0.4780 - val_accuracy: 0.8296\n",
      "Epoch 2/30\n",
      "71/71 [==============================] - 42s 598ms/step - loss: 0.3526 - accuracy: 0.8605 - val_loss: 0.5565 - val_accuracy: 0.8113\n",
      "Epoch 3/30\n",
      "71/71 [==============================] - 42s 591ms/step - loss: 0.3150 - accuracy: 0.8757 - val_loss: 0.3395 - val_accuracy: 0.9051\n",
      "Epoch 4/30\n",
      "71/71 [==============================] - 42s 596ms/step - loss: 0.2829 - accuracy: 0.8889 - val_loss: 0.2680 - val_accuracy: 0.9084\n",
      "Epoch 5/30\n",
      "71/71 [==============================] - 43s 607ms/step - loss: 0.2600 - accuracy: 0.8995 - val_loss: 0.4276 - val_accuracy: 0.8452\n",
      "Epoch 6/30\n",
      "71/71 [==============================] - 43s 601ms/step - loss: 0.2475 - accuracy: 0.9024 - val_loss: 0.2741 - val_accuracy: 0.9034\n",
      "Epoch 7/30\n",
      "71/71 [==============================] - 43s 602ms/step - loss: 0.2372 - accuracy: 0.9067 - val_loss: 0.2438 - val_accuracy: 0.9290\n",
      "Epoch 8/30\n",
      "71/71 [==============================] - 42s 595ms/step - loss: 0.2297 - accuracy: 0.9109 - val_loss: 0.2786 - val_accuracy: 0.9240\n",
      "Epoch 9/30\n",
      "71/71 [==============================] - 43s 602ms/step - loss: 0.2300 - accuracy: 0.9104 - val_loss: 0.2376 - val_accuracy: 0.9270\n",
      "Epoch 10/30\n",
      "71/71 [==============================] - 44s 613ms/step - loss: 0.2185 - accuracy: 0.9142 - val_loss: 0.3813 - val_accuracy: 0.9021\n",
      "Epoch 11/30\n",
      "71/71 [==============================] - 43s 609ms/step - loss: 0.2125 - accuracy: 0.9165 - val_loss: 0.2137 - val_accuracy: 0.9285\n",
      "Epoch 12/30\n",
      "71/71 [==============================] - 43s 611ms/step - loss: 0.2085 - accuracy: 0.9201 - val_loss: 0.2081 - val_accuracy: 0.9297\n",
      "Epoch 13/30\n",
      "71/71 [==============================] - 43s 604ms/step - loss: 0.2122 - accuracy: 0.9186 - val_loss: 0.1960 - val_accuracy: 0.9365\n",
      "Epoch 14/30\n",
      "71/71 [==============================] - 43s 605ms/step - loss: 0.2079 - accuracy: 0.9185 - val_loss: 0.2171 - val_accuracy: 0.9340\n",
      "Epoch 15/30\n",
      "71/71 [==============================] - 43s 601ms/step - loss: 0.2022 - accuracy: 0.9227 - val_loss: 0.2290 - val_accuracy: 0.9159\n",
      "Epoch 16/30\n",
      "71/71 [==============================] - 43s 603ms/step - loss: 0.2205 - accuracy: 0.9170 - val_loss: 0.2692 - val_accuracy: 0.9114\n",
      "Epoch 17/30\n",
      "71/71 [==============================] - 43s 606ms/step - loss: 0.2019 - accuracy: 0.9221 - val_loss: 0.2395 - val_accuracy: 0.9338\n",
      "Epoch 18/30\n",
      "71/71 [==============================] - 42s 596ms/step - loss: 0.1943 - accuracy: 0.9253 - val_loss: 0.1717 - val_accuracy: 0.9423\n",
      "Epoch 19/30\n",
      "71/71 [==============================] - 42s 593ms/step - loss: 0.2299 - accuracy: 0.9126 - val_loss: 0.1658 - val_accuracy: 0.9428\n",
      "Epoch 20/30\n",
      "71/71 [==============================] - 42s 597ms/step - loss: 0.1920 - accuracy: 0.9260 - val_loss: 0.1889 - val_accuracy: 0.9413\n",
      "Epoch 21/30\n",
      "71/71 [==============================] - 43s 602ms/step - loss: 0.1880 - accuracy: 0.9284 - val_loss: 0.1807 - val_accuracy: 0.9423\n",
      "Epoch 22/30\n",
      "71/71 [==============================] - 42s 589ms/step - loss: 0.1800 - accuracy: 0.9311 - val_loss: 0.1865 - val_accuracy: 0.9393\n",
      "Epoch 23/30\n",
      "71/71 [==============================] - 42s 592ms/step - loss: 0.1828 - accuracy: 0.9315 - val_loss: 0.1991 - val_accuracy: 0.9343\n",
      "Epoch 24/30\n",
      "71/71 [==============================] - 43s 601ms/step - loss: 0.1778 - accuracy: 0.9311 - val_loss: 0.1846 - val_accuracy: 0.9458\n",
      "Epoch 25/30\n",
      "71/71 [==============================] - 43s 600ms/step - loss: 0.1816 - accuracy: 0.9309 - val_loss: 0.1608 - val_accuracy: 0.9465\n",
      "Epoch 26/30\n",
      "71/71 [==============================] - 43s 604ms/step - loss: 0.1838 - accuracy: 0.9296 - val_loss: 0.1823 - val_accuracy: 0.9438\n",
      "Epoch 27/30\n",
      "71/71 [==============================] - 43s 604ms/step - loss: 0.1829 - accuracy: 0.9291 - val_loss: 0.1637 - val_accuracy: 0.9458\n",
      "Epoch 28/30\n",
      "71/71 [==============================] - 42s 596ms/step - loss: 0.1750 - accuracy: 0.9337 - val_loss: 0.2351 - val_accuracy: 0.9330\n",
      "Epoch 29/30\n",
      "71/71 [==============================] - 42s 588ms/step - loss: 0.1866 - accuracy: 0.9284 - val_loss: 0.1929 - val_accuracy: 0.9425\n",
      "Epoch 30/30\n",
      "71/71 [==============================] - 42s 589ms/step - loss: 0.1774 - accuracy: 0.9338 - val_loss: 0.2007 - val_accuracy: 0.9420\n"
     ]
    }
   ],
   "source": [
    "# fit model with the training data\n",
    "\n",
    "history3 = model3.fit(xtrain_padding3, y=ytrain_encode3, batch_size=512, validation_data=(xvalid_padding3, yvalid_encode3), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: summary3_b.hd5/assets\n"
     ]
    }
   ],
   "source": [
    "# save 3 sentence summary model data\n",
    "\n",
    "model3.save(\"summary3_b.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 69ms/step\n"
     ]
    }
   ],
   "source": [
    "# predict on test set\n",
    "\n",
    "y_pred3 = model3.predict(x = xtest_padding3, batch_size = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert probabilities to binaries\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred_class3 = np.where(y_pred3 > threshold, 1, 0)\n",
    "y_pred_int3 = []\n",
    "for i in range(len(y_pred_class3)):\n",
    "    if y_pred_class3[i][0] == 1:\n",
    "        y_pred_int3.append(0)\n",
    "    elif y_pred_class3[i][0] == 0:\n",
    "        y_pred_int3.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1978,   49],\n",
       "       [ 186, 2214]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm3 = confusion_matrix(y_pred_int3, ytest3)\n",
    "cm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['summ3', 0.9783473265576668, 0.9225, 0.946916647842783]\n"
     ]
    }
   ],
   "source": [
    "# calculate performance measures\n",
    "\n",
    "p3 = precision_score(y_pred_int3, ytest3)\n",
    "r3 = recall_score(y_pred_int3, ytest3)\n",
    "a3 = accuracy_score(y_pred_int3, ytest3)\n",
    "perf3 = [\"summ3\",p3,r3,a3]\n",
    "print(perf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# create bidirectional LSTM model for 4 sentence summaries\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(Embedding(len(word_index) + 1,\n",
    " 50,\n",
    " weights=[embedding_matrix],\n",
    " input_length=MAX_LENGTH,\n",
    " trainable=False))\n",
    "model4.add(SpatialDropout1D(0.3))\n",
    "model4.add(Bidirectional(LSTM(100, dropout=0.3, recurrent_dropout=0.3)))\n",
    "model4.add(Dense(1024, activation='relu'))\n",
    "model4.add(Dropout(0.8))\n",
    "model4.add(Dense(1024, activation='relu'))\n",
    "model4.add(Dropout(0.8))\n",
    "model4.add(Dense(2))\n",
    "model4.add(Activation('sigmoid'))\n",
    "model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "71/71 [==============================] - 45s 600ms/step - loss: 0.4656 - accuracy: 0.7820 - val_loss: 0.3396 - val_accuracy: 0.8801\n",
      "Epoch 2/30\n",
      "71/71 [==============================] - 42s 593ms/step - loss: 0.3610 - accuracy: 0.8573 - val_loss: 0.2476 - val_accuracy: 0.9114\n",
      "Epoch 3/30\n",
      "71/71 [==============================] - 42s 595ms/step - loss: 0.3107 - accuracy: 0.8802 - val_loss: 0.2851 - val_accuracy: 0.9072\n",
      "Epoch 4/30\n",
      "71/71 [==============================] - 42s 588ms/step - loss: 0.2746 - accuracy: 0.8919 - val_loss: 0.2538 - val_accuracy: 0.9182\n",
      "Epoch 5/30\n",
      "71/71 [==============================] - 42s 597ms/step - loss: 0.2605 - accuracy: 0.9013 - val_loss: 0.3837 - val_accuracy: 0.8763\n",
      "Epoch 6/30\n",
      "71/71 [==============================] - 43s 608ms/step - loss: 0.2468 - accuracy: 0.9055 - val_loss: 0.2217 - val_accuracy: 0.9265\n",
      "Epoch 7/30\n",
      "71/71 [==============================] - 42s 598ms/step - loss: 0.2335 - accuracy: 0.9111 - val_loss: 0.2782 - val_accuracy: 0.9019\n",
      "Epoch 8/30\n",
      "71/71 [==============================] - 42s 596ms/step - loss: 0.2259 - accuracy: 0.9146 - val_loss: 0.1981 - val_accuracy: 0.9199\n",
      "Epoch 9/30\n",
      "71/71 [==============================] - 43s 603ms/step - loss: 0.2215 - accuracy: 0.9180 - val_loss: 0.2045 - val_accuracy: 0.9267\n",
      "Epoch 10/30\n",
      "71/71 [==============================] - 42s 599ms/step - loss: 0.2221 - accuracy: 0.9176 - val_loss: 0.2321 - val_accuracy: 0.9107\n",
      "Epoch 11/30\n",
      "71/71 [==============================] - 43s 599ms/step - loss: 0.2161 - accuracy: 0.9189 - val_loss: 0.2099 - val_accuracy: 0.9222\n",
      "Epoch 12/30\n",
      "71/71 [==============================] - 42s 587ms/step - loss: 0.2074 - accuracy: 0.9230 - val_loss: 0.1958 - val_accuracy: 0.9420\n",
      "Epoch 13/30\n",
      "71/71 [==============================] - 44s 614ms/step - loss: 0.1986 - accuracy: 0.9241 - val_loss: 0.1842 - val_accuracy: 0.9405\n",
      "Epoch 14/30\n",
      "71/71 [==============================] - 42s 593ms/step - loss: 0.1961 - accuracy: 0.9285 - val_loss: 0.1549 - val_accuracy: 0.9468\n",
      "Epoch 15/30\n",
      "71/71 [==============================] - 49s 691ms/step - loss: 0.1922 - accuracy: 0.9294 - val_loss: 0.2096 - val_accuracy: 0.9297\n",
      "Epoch 16/30\n",
      "71/71 [==============================] - 46s 642ms/step - loss: 0.2016 - accuracy: 0.9256 - val_loss: 0.1604 - val_accuracy: 0.9445\n",
      "Epoch 17/30\n",
      "71/71 [==============================] - 43s 607ms/step - loss: 0.1859 - accuracy: 0.9303 - val_loss: 0.1767 - val_accuracy: 0.9350\n",
      "Epoch 18/30\n",
      "71/71 [==============================] - 43s 601ms/step - loss: 0.1845 - accuracy: 0.9324 - val_loss: 0.1399 - val_accuracy: 0.9521\n",
      "Epoch 19/30\n",
      "71/71 [==============================] - 43s 605ms/step - loss: 0.1795 - accuracy: 0.9331 - val_loss: 0.1415 - val_accuracy: 0.9516\n",
      "Epoch 20/30\n",
      "71/71 [==============================] - 43s 605ms/step - loss: 0.1819 - accuracy: 0.9323 - val_loss: 0.1520 - val_accuracy: 0.9491\n",
      "Epoch 21/30\n",
      "71/71 [==============================] - 44s 615ms/step - loss: 0.1783 - accuracy: 0.9345 - val_loss: 0.1267 - val_accuracy: 0.9538\n",
      "Epoch 22/30\n",
      "71/71 [==============================] - 43s 608ms/step - loss: 0.1766 - accuracy: 0.9352 - val_loss: 0.1450 - val_accuracy: 0.9483\n",
      "Epoch 23/30\n",
      "71/71 [==============================] - 43s 603ms/step - loss: 0.1737 - accuracy: 0.9348 - val_loss: 0.1383 - val_accuracy: 0.9476\n",
      "Epoch 24/30\n",
      "71/71 [==============================] - 43s 606ms/step - loss: 0.1765 - accuracy: 0.9342 - val_loss: 0.1486 - val_accuracy: 0.9498\n",
      "Epoch 25/30\n",
      "71/71 [==============================] - 43s 605ms/step - loss: 0.1702 - accuracy: 0.9366 - val_loss: 0.1250 - val_accuracy: 0.9546\n",
      "Epoch 26/30\n",
      "71/71 [==============================] - 42s 593ms/step - loss: 0.1698 - accuracy: 0.9397 - val_loss: 0.1464 - val_accuracy: 0.9523\n",
      "Epoch 27/30\n",
      "71/71 [==============================] - 43s 610ms/step - loss: 0.1660 - accuracy: 0.9399 - val_loss: 0.1417 - val_accuracy: 0.9508\n",
      "Epoch 28/30\n",
      "71/71 [==============================] - 43s 604ms/step - loss: 0.1651 - accuracy: 0.9398 - val_loss: 0.1310 - val_accuracy: 0.9543\n",
      "Epoch 29/30\n",
      "71/71 [==============================] - 43s 603ms/step - loss: 0.1701 - accuracy: 0.9365 - val_loss: 0.1501 - val_accuracy: 0.9521\n",
      "Epoch 30/30\n",
      "71/71 [==============================] - 43s 607ms/step - loss: 0.1644 - accuracy: 0.9414 - val_loss: 0.1184 - val_accuracy: 0.9571\n"
     ]
    }
   ],
   "source": [
    "# fit model with the training data\n",
    "\n",
    "history4 = model4.fit(xtrain_padding4, y=ytrain_encode4, batch_size=512, validation_data=(xvalid_padding4, yvalid_encode4), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: summary4_b.hd5/assets\n"
     ]
    }
   ],
   "source": [
    "# save 4 sentence summary model data\n",
    "\n",
    "model4.save(\"summary4_b.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 67ms/step\n"
     ]
    }
   ],
   "source": [
    "# predict on test set\n",
    "\n",
    "y_pred4 = model4.predict(x = xtest_padding4, batch_size = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert probabilities to binaries\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred_class4 = np.where(y_pred4 > threshold, 1, 0)\n",
    "y_pred_int4 = []\n",
    "for i in range(len(y_pred_class4)):\n",
    "    if y_pred_class4[i][0] == 1:\n",
    "        y_pred_int4.append(0)\n",
    "    elif y_pred_class4[i][0] == 0:\n",
    "        y_pred_int4.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2028,   99],\n",
       "       [ 117, 2183]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm4 = confusion_matrix(y_pred_int4, ytest4)\n",
    "cm4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['summ4', 0.9566170026292725, 0.9491304347826087, 0.9512084933363452]\n"
     ]
    }
   ],
   "source": [
    "# calculate performance measures\n",
    "\n",
    "p4 = precision_score(y_pred_int4, ytest4)\n",
    "r4 = recall_score(y_pred_int4, ytest4)\n",
    "a4 = accuracy_score(y_pred_int4, ytest4)\n",
    "perf4 = [\"summ4\",p4,r4,a4]\n",
    "print(perf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 750x750 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2,2, figsize=(7.5, 7.5))\n",
    "axs[0,0].matshow(cm1, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(cm1.shape[0]):\n",
    "    for j in range(cm1.shape[1]):\n",
    "        axs[0,0].text(x=j, y=i,s=cm1[i, j], va='center', ha='center', size='x-large')\n",
    "axs[0,0].set_title('Titles', size= 'large')\n",
    "axs[0,1].matshow(cm2, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(cm2.shape[0]):\n",
    "    for j in range(cm2.shape[1]):\n",
    "        axs[0,1].text(x=j, y=i,s=cm2[i, j], va='center', ha='center', size='x-large')\n",
    "axs[0,1].set_title('Whole Texts', size= 'large')\n",
    "axs[1,0].matshow(cm3, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(cm3.shape[0]):\n",
    "    for j in range(cm3.shape[1]):\n",
    "        axs[1,0].text(x=j, y=i,s=cm3[i, j], va='center', ha='center', size='x-large')\n",
    "axs[1,0].set_title('Summary - 3', size= 'large')\n",
    "axs[1,1].matshow(cm4, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(cm4.shape[0]):\n",
    "    for j in range(cm4.shape[1]):\n",
    "        axs[1,1].text(x=j, y=i,s=cm4[i, j], va='center', ha='center', size='x-large')\n",
    "axs[1,1].set_title('Summary - 4', size= 'large')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel = \"Actuals\", ylabel = \"Predictions\")\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>titles</td>\n",
       "      <td>0.917476</td>\n",
       "      <td>0.951923</td>\n",
       "      <td>0.934041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>whole texts</td>\n",
       "      <td>0.991270</td>\n",
       "      <td>0.944283</td>\n",
       "      <td>0.965213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>summ3</td>\n",
       "      <td>0.978347</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.946917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>summ4</td>\n",
       "      <td>0.956617</td>\n",
       "      <td>0.949130</td>\n",
       "      <td>0.951208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model  precision    recall  accuracy\n",
       "0       titles   0.917476  0.951923  0.934041\n",
       "1  whole texts   0.991270  0.944283  0.965213\n",
       "2        summ3   0.978347  0.922500  0.946917\n",
       "3        summ4   0.956617  0.949130  0.951208"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame([perf1,perf2,perf3,perf4], columns = ['model','precision','recall','accuracy'])\n",
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cdfeaaf558222e6152d1b8b5608a6b3851c7ad1b1c88c0f374f1fb0a85757022"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
